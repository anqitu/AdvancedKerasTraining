{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 Backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "x = K.placeholder(shape=(4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "var = K.variable(np.random.random((3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import inception_v3\n",
    "from keras import backend as K\n",
    "\n",
    "# We will not be training our model,\n",
    "# so we use this command to disable all training-specific operations\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# Build the InceptionV3 network.\n",
    "# The model will be loaded with pre-trained ImageNet weights.\n",
    "model = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "#print(model.summary())\n",
    "# Dict mapping layer names to a coefficient\n",
    "# quantifying how much the layer's activation\n",
    "# will contribute to the loss we will seek to maximize.\n",
    "# Note that these are layer names as they appear\n",
    "# in the built-in InceptionV3 application.\n",
    "# You can list all layer names using `model.summary()`.\n",
    "layer_contributions = {\n",
    "    'mixed2': 0.2,\n",
    "    'mixed3': 3.,\n",
    "    'mixed4': 2.,\n",
    "    'mixed5': 1.5,\n",
    "}\n",
    "\n",
    "# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# Define the loss.\n",
    "loss = K.variable(0.)\n",
    "for layer_name in layer_contributions:\n",
    "    # Add the L2 norm of the features of a layer to the loss.\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    activation = layer_dict[layer_name].output\n",
    "\n",
    "    # We avoid border artifacts by only involving non-border pixels in the loss.\n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling\n",
    "\n",
    "# This holds our generated image\n",
    "dream = model.input\n",
    "\n",
    "# Compute the gradients of the dream with regard to the loss.\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "\n",
    "# Normalize gradients.\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
    "\n",
    "# Set up function to retrieve the value\n",
    "# of the loss and gradients given an input image.\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...Loss value at', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x\n",
    "\n",
    "import scipy\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1,\n",
    "               float(size[0]) / img.shape[1],\n",
    "               float(size[1]) / img.shape[2],\n",
    "               1)\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    scipy.misc.imsave(fname, pil_img)\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Util function to open, resize and format pictures\n",
    "    # into appropriate tensors.\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Util function to convert a tensor into a valid image.\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Playing with these hyperparameters will also allow you to achieve new effects\n",
    "\n",
    "step = 0.01  # Gradient ascent step size\n",
    "num_octave = 3  # Number of scales at which to run gradient ascent\n",
    "octave_scale = 1.4  # Size ratio between scales\n",
    "iterations = 20  # Number of ascent steps per scale\n",
    "\n",
    "# If our loss gets larger than 10,\n",
    "# we will interrupt the gradient ascent process, to avoid ugly artifacts\n",
    "max_loss = 10.\n",
    "\n",
    "# Fill this to the path to the image you want to use\n",
    "base_image_path = './images/vincent.jpg'\n",
    "\n",
    "# Load the image into a Numpy array\n",
    "img = preprocess_image(base_image_path)\n",
    "\n",
    "# We prepare a list of shape tuples\n",
    "# defining the different scales at which we will run gradient ascent\n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "\n",
    "# Reverse list of shapes, so that they are in increasing order\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "# Resize the Numpy array of the image to our smallest scale\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Processing image shape', shape)\n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                          iterations=iterations,\n",
    "                          step=step,\n",
    "                          max_loss=max_loss)\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    save_img(img, fname='./images/dream_' + str(shape) + '.png')\n",
    "\n",
    "save_img(img, fname='./images/final_dream.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex: Custom Loss Function Using Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def customLoss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)+K.mean(K.abs(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.linspace(1,10,10)\n",
    "y_train = 2*x_train + 5*np.random.random(len(x_train))\n",
    "\n",
    "inputs = Input(shape=(1,))\n",
    "output = Dense(1, activation='linear')(inputs)\n",
    "model = Model(inputs, output)\n",
    "\n",
    "\n",
    "model.compile(optimizer='sgd', loss=customLoss)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, verbose=0)\n",
    "\n",
    "x_test = np.array([3,5])\n",
    "\n",
    "yhat = model.predict(x_train)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_train,y_train,'o')\n",
    "plt.plot(x_train,yhat,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
