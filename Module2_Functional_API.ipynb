{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API implementation of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.linspace(1,10,10)\n",
    "y_train = 2*x_train + 5*np.random.random(len(x_train))\n",
    "\n",
    "inputs = Input(shape=(1,))\n",
    "output = Dense(1, activation='linear')(inputs)\n",
    "model = Model(inputs, output)\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, verbose=0)\n",
    "\n",
    "x_test = np.array([3,5])\n",
    "\n",
    "yhat = model.predict(x_train)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_train,y_train,'o')\n",
    "plt.plot(x_train,yhat,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Step 1:Load the Data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequental Model for Feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64,input_dim=784,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=2,batch_size=100)\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test)\n",
    "print(\"Accuracy \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex: Functional API on Feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "inputs = Input(shape=(784,))\n",
    "hidden1 = Dense(64,activation='relu')(inputs)\n",
    "hidden2 = Dense(64,activation='relu')(hidden1)\n",
    "output = Dense(10,activation='softmax')(hidden2)\n",
    "model = Model(inputs, output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=2,batch_size=100)\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test)\n",
    "print(\"Accuracy \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequental Model for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D,MaxPooling2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=(28,28,1),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=2,batch_size=100)\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test)\n",
    "print(\"Accuracy \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex: Functional API on CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D,MaxPooling2D,Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "inputs = Input((28,28,1))\n",
    "conv1 = Conv2D(32,(3,3),activation='relu',padding='same')(inputs)\n",
    "conv1 = MaxPooling2D((2,2))(conv1)\n",
    "conv2 = Conv2D(32,(3,3),activation='relu',padding='same')(conv1)\n",
    "conv2 = MaxPooling2D((2,2))(conv2)\n",
    "conv2 = Flatten()(conv2)\n",
    "dense1 = Dense(256,activation='relu')(conv2)\n",
    "output = Dense(10,activation='softmax')(dense1)\n",
    "model = Model(inputs,output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=2,batch_size=100)\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test)\n",
    "print(\"Accuracy \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "# Number of words to consider as features\n",
    "max_features = 10000\n",
    "\n",
    "# Cut texts after this number of words \n",
    "maxlen = 20\n",
    "\n",
    "# Load the data as lists of integers.\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequental Model for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 50))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_test,y_test))\n",
    "\n",
    "# loss,accuracy = model.evaluate(X_test,y_test)\n",
    "# print(\"Accuracy \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex: Functional API on RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Input\n",
    "\n",
    "inputs = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedding = Embedding(max_features, 50)(inputs)\n",
    "lstm = LSTM(32)(embedding)\n",
    "output = Dense(1, activation='sigmoid')(lstm)\n",
    "model = Model(inputs,output)\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=2,validation_data=(X_test,y_test))\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test)\n",
    "print(\"Accuracy \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Funcational API to Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = \"./images/cats_dogs/\"\n",
    "img_width, img_height = 224, 224\n",
    "epochs = 1\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                        directory=train_data_dir,\n",
    "                        target_size=[img_width, img_height],\n",
    "                        class_mode='categorical')\n",
    "\n",
    "# Step 2-1: Replace softmax Layer and add one dense layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "prediction = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=prediction)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,steps_per_epoch=10,epochs=epochs)\n",
    "\n",
    "# Step 2-2: Unfreeze and train the top 5 layers\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[5:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,steps_per_epoch=10,epochs=epochs)\n",
    "\n",
    "# Save fine tuned weight\n",
    "model.save('./models/vgg16_cat_dog.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Functional API to GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "\n",
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "\n",
    "# Optimizer\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "generator = Sequential()\n",
    "generator.add(Dense(256, input_dim=randomDim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(512))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(1024))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(784, activation='tanh'))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(512))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(256))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "\n",
    "# Combined network\n",
    "discriminator.trainable = False\n",
    "ganInput = Input(shape=(randomDim,))\n",
    "x = generator(ganInput)\n",
    "ganOutput = discriminator(x)\n",
    "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex: Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.3753 - acc: 0.8819\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 18s 304us/step - loss: 0.1003 - acc: 0.9697\n",
      "10000/10000 [==============================] - 1s 117us/step\n",
      "Accuracy  0.9763\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D,MaxPooling2D,Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# input layer\n",
    "\n",
    "inputs = Input((28,28,1))\n",
    "\n",
    "# first feature extractor\n",
    "conv1 = Conv2D(32, kernel_size=4, activation='relu')(inputs)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "flat1 = Flatten()(pool1)\n",
    "\n",
    "# second feature extractor\n",
    "conv2 = Conv2D(16, kernel_size=8, activation='relu')(inputs)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "flat2 = Flatten()(pool2)\n",
    "\n",
    "# merge feature extractors\n",
    "merge = concatenate([flat1, flat2])\n",
    "\n",
    "# interpretation layer\n",
    "hidden1 = Dense(10, activation='relu')(merge)\n",
    "\n",
    "# prediction output\n",
    "output = Dense(10,activation='softmax')(hidden1)\n",
    "model = Model(inputs,output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=2,batch_size=100)\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test,y_test)\n",
    "print(\"Accuracy \",accuracy)\n",
    "\n",
    "# summarize layers\n",
    "#print(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
